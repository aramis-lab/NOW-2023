# 9 September 2023

## Attendees

- Nicolas
- Matthieu

## Discussion

The goals were to discuss a possible outline for the workshop as well as possible ideas for exercices.

- 3 hours to be split in roughly 1h of presentation and 2h of practice.
	- Would be best to avoid doing 1h of presentation and then 2 hours of practice...
	- Split presentation and practical work on the different topics that we want to cover.

- Probably need to take about 20min to 30min at the begining to:
	- explain what the goals of the workshop are
	- explain the outline of the workshop
	- make sure everybody has access to the internet
	- make sure everybody made the requirements (install stuffs, download needed data, read something...) and is ready to work
	- we need to think about all plateforms here (especially Windows which is always a pain...)

- A possible outline is the following (assuming a 9h - 12h session without breaks...) :
	- 9h - 9h30 : Explain the workshop objectives and make sure everyone is ready to go.
	- 9h30 - 10h : Presentation on code versioning
		- What is code versioning ?
		- Why do we need code versioning ?
		- How can we achieve it ? (Present Git and mention other alternatives such as SVN)
		- How to work with Git ? (Present here the main concepts and the ones we will need for DVC)
	- 10h - 10h45 : Exercices on code versioning (see details below)
	- 10h45 - 11h15 : Presentation on data versioning
		- What is data versioning ?
		- Why do we need it ? (This need should have arised from the exercice on code versioning...)
		- How can we achieve it ? (Present DVC but mention alternatives such as Git-annex, datalad, or Git-LFS...)
		- How to work with DVC ?
	- 11h15 - 11h50 : Exercices on code + data versioning (see details below)
	- 11h50 - 12h : Concluding remarks

- It would be great to have a working example on which to iterate along the workshop
	- We thought about building a model capable of predicting whether a subject has Alzeihmer or not
	- The idea is to start with a very simple dataset and a very simple model
		- The dataset could be a simple CSV file with a single feature like the hyppocampus volume (values would be precomputed by us beforehand)
		- We could rely on Oasis3 for that since it is open (would avoid making people sign agreements...)
		- The model would be very simple first and possibly partially implemented such that :
			- a task of the exercice could be to implement missing pieces and make commits along the way
			- another task could be to implement a better model
		- At this point, we assume that everything is versionned using Git (same repo for code and data ??)
		- A possible next step could be to have a dataset update. For example a few more features become available (what features ??)
		- Users will version their data with git
		- Users will implement a new multivariate model and compare the results with the first univariate models
	- The idea is then to explain that the dataset provided for these first exercices comes from brain images and code which extracts these metrics
	- This lead us to having very different data inputs to our experiments (from CSV files to nifti images)
	- These images cannot be handled with Git such that we need a new tool for this: DVC
	- The first exercice of the data versioning section could be to make the same experiment as on the code versioning section, but starting from images instead of extracted values
	- PROBLEM : We need some code performing this extraction that:
		- is relatively fast
		- is easy to run (meaning basically implemented in pure Python (nibabel, nilearn...). Freesufer, SPM, and pals are definitely not an option here...)
		- We could perform the computations beforehand and give users a derivative from which it is easy to obtain the metrics of interest
		- For example, we could pre-compute masks for the hyppocampus for every subject and give these masks as nifti images in MNI space
		- The users then "only" need to compute the volume from the mask which can be done using Nibabel and Numpy (too trivial ??)
		- We could also rely on Atlases to perform this task (Nilearn has some fetchers for example)
		- If we proceed like this, it would be good to also share the code we used to compute the derivatives (otherwise it defeats the purpose of open science...)
	
- We could also present DVC's experiment management capabilities
	- This enables you to describe the steps of your experiments using YAML syntax
	- Each step depends on code and data
	- If code and/or data is modified, DVC will automatically run the steps that are impacted
	- This would answer the question of coherence between code and data version
