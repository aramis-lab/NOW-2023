{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf04b33b",
   "metadata": {},
   "source": [
    "# Part 1 : Code versionning using GIT\n",
    "\n",
    "This is the first part of the tutorial on code versioning using git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from time import time\n",
    "from os import path\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc88a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset\n",
    "OASIS_df = pd.read_csv(\n",
    "    'OASIS-1_dataset/tsv_files/lab_1/OASIS_BIDS.tsv', sep='\\t',\n",
    "    usecols=['participant_id', 'session_id', 'alternative_id_1', 'sex',\n",
    "             'education_level', 'age_bl', 'diagnosis_bl', 'laterality', 'MMS',\n",
    "             'cdr_global', 'diagnosis']\n",
    ")\n",
    "# Show first items of the table\n",
    "print(OASIS_df.head())\n",
    "# First visual inspection\n",
    "_ = OASIS_df.hist(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c865e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study the characteristics of the AD & CN populations (age, sex, MMS, cdr_global)\n",
    "from training import characteristics_table\n",
    "\n",
    "population_df = characteristics_table(OASIS_df, OASIS_df)\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING ###\n",
    "from training import MRIDataset, CropLeftHC, CropRightHC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420abbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZATION ###\n",
    "from training import show_slices\n",
    "\n",
    "subject = 'sub-OASIS10003'\n",
    "preprocessed_pt = torch.load(f'OASIS-1_dataset/CAPS/subjects/{subject}/ses-M00/' +\n",
    "                    f'deeplearning_prepare_data/image_based/custom/{subject}_ses-M00_' +\n",
    "                    'T1w_segm-graymatter_space-Ixi549Space_modulated-off_' +\n",
    "                    'probability.pt')\n",
    "raw_nii = nib.load(f'OASIS-1_dataset/raw/{subject}_ses-M00_T1w.nii.gz')\n",
    "\n",
    "raw_np = raw_nii.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392bf5f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "slice_0 = raw_np[:, :, 78]\n",
    "slice_1 = raw_np[122, :, :]\n",
    "slice_2 = raw_np[:, 173, :]\n",
    "show_slices([slice_0, rotate(slice_1, 90), rotate(slice_2, 90)])\n",
    "plt.suptitle(f'Slices of raw image of subject {subject}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232895ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = preprocessed_pt[0, 60, :, :]\n",
    "slice_1 = preprocessed_pt[0, :, 72, :]\n",
    "slice_2 = preprocessed_pt[0, :, :, 60]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(f'Center slices of preprocessed image of subject {subject}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f9d4f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "leftHC_pt = CropLeftHC()(preprocessed_pt)\n",
    "slice_0 = leftHC_pt[0, 15, :, :]\n",
    "slice_1 = leftHC_pt[0, :, 20, :]\n",
    "slice_2 = leftHC_pt[0, :, :, 15]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(f'Center slices of left HC of subject {subject}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CROSS VALIDATION ###\n",
    "\n",
    "train_df = pd.read_csv('OASIS-1_dataset/tsv_files/lab_1/train.tsv', sep='\\t')\n",
    "valid_df = pd.read_csv('OASIS-1_dataset/tsv_files/lab_1/validation.tsv', sep='\\t')\n",
    "\n",
    "train_population_df = characteristics_table(train_df, OASIS_df)\n",
    "valid_population_df = characteristics_table(valid_df, OASIS_df)\n",
    "\n",
    "print(f\"Train dataset:\\n {train_population_df}\\n\")\n",
    "print(f\"Validation dataset:\\n {valid_population_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba7ca3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "from torch.utils.data import DataLoader\n",
    "img_dir = path.join('OASIS-1_dataset', 'CAPS')\n",
    "batch_size=4\n",
    "\n",
    "example_dataset = MRIDataset(img_dir, OASIS_df, transform=CropLeftHC())\n",
    "example_dataloader = DataLoader(example_dataset, batch_size=batch_size, drop_last=True)\n",
    "for data in example_dataloader:\n",
    "    pass\n",
    "\n",
    "print(f\"Shape of Dataset output:\\n {example_dataset[0]['image'].shape}\\n\")\n",
    "\n",
    "print(f\"Shape of DataLoader output:\\n {data['image'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eacb64",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### TRAIN WITH LEFT HC ###\n",
    "\n",
    "from training import CustomNetwork, train, test\n",
    "img_dir = path.join('/Users/camille.brianceau/Downloads/OASIS-1_dataset', 'CAPS')\n",
    "transform = CropLeftHC(2)\n",
    "\n",
    "train_datasetLeftHC = MRIDataset(img_dir, train_df, transform=transform)\n",
    "valid_datasetLeftHC = MRIDataset(img_dir, valid_df, transform=transform)\n",
    "\n",
    "# Try different learning rates\n",
    "learning_rate = 10**-4\n",
    "n_epochs = 30\n",
    "batch_size = 4\n",
    "\n",
    "# Put the network on GPU\n",
    "modelLeftHC = CustomNetwork() #.cuda()\n",
    "train_loaderLeftHC = DataLoader(train_datasetLeftHC, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "# A high batch size improves test speed\n",
    "valid_loaderLeftHC = DataLoader(valid_datasetLeftHC, batch_size=32, shuffle=False, pin_memory=True)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(modelLeftHC.parameters(), learning_rate)\n",
    "\n",
    "best_modelLeftHC = train(modelLeftHC, train_loaderLeftHC, criterion, optimizer, n_epochs)\n",
    "\n",
    "valid_resultsLeftHC_df, valid_metricsLeftHC = test(best_modelLeftHC, valid_loaderLeftHC, criterion)\n",
    "train_resultsLeftHC_df, train_metricsLeftHC = test(best_modelLeftHC, train_loaderLeftHC, criterion)\n",
    "print(valid_metricsLeftHC)\n",
    "print(train_metricsLeftHC)\n",
    "\n",
    "\n",
    "valid_resultsLeftHC_df = valid_resultsLeftHC_df.merge(OASIS_df, how='left', on='participant_id', sort=False)\n",
    "valid_resultsLeftHC_old_df = valid_resultsLeftHC_df[(valid_resultsLeftHC_df.age_bl >= 62)]\n",
    "#compute_metrics(valid_resultsLeftHC_old_df.true_label, valid_resultsLeftHC_old_df.predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f04112",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN WITH RIGHT HC ###\n",
    "img_dir = path.join('/Users/camille.brianceau/Downloads/OASIS-1_dataset', 'CAPS')\n",
    "transform = CropRightHC(2)\n",
    "\n",
    "train_datasetRightHC = MRIDataset(img_dir, train_df, transform=transform)\n",
    "valid_datasetRightHC = MRIDataset(img_dir, valid_df, transform=transform)\n",
    "\n",
    "learning_rate = 10**-4\n",
    "n_epochs = 30\n",
    "batch_size = 4\n",
    "\n",
    "# Put the network on GPU\n",
    "modelRightHC = CustomNetwork() #.cuda()\n",
    "train_loaderRightHC = DataLoader(train_datasetRightHC, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "valid_loaderRightHC = DataLoader(valid_datasetRightHC, batch_size=32, shuffle=False,  pin_memory=True)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(modelRightHC.parameters(), learning_rate)\n",
    "\n",
    "best_modelRightHC = train(modelRightHC, train_loaderRightHC, criterion, optimizer, n_epochs)\n",
    "\n",
    "valid_resultsRightHC_df, valid_metricsRightHC = test(best_modelRightHC, valid_loaderRightHC, criterion)\n",
    "train_resultsRightHC_df, train_metricsRightHC = test(best_modelRightHC, train_loaderRightHC, criterion)\n",
    "print(valid_metricsRightHC)\n",
    "print(train_metricsRightHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e0a70",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from training import compute_metrics\n",
    "### SOFT VOTING ###\n",
    "\n",
    "def softvoting(leftHC_df, rightHC_df):\n",
    "    df1 = leftHC_df.set_index('participant_id', drop=True)\n",
    "    df2 = rightHC_df.set_index('participant_id', drop=True)\n",
    "    results_df = pd.DataFrame(index=df1.index.values,\n",
    "                              columns=['true_label', 'predicted_label',\n",
    "                                       'proba0', 'proba1'])\n",
    "    results_df.true_label = df1.true_label\n",
    "    # Compute predicted label and probabilities\n",
    "    results_df.proba1 = 0.5 * df1.proba1 + 0.5 * df2.proba1\n",
    "    results_df.proba0 = 0.5 * df1.proba0 + 0.5 * df2.proba0\n",
    "    results_df.predicted_label = (0.5 * df1.proba1 + 0.5 * df2.proba1 > 0.5).astype(int)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "valid_results = softvoting(valid_resultsLeftHC_df, valid_resultsRightHC_df)\n",
    "valid_metrics = compute_metrics(valid_results.true_label, valid_results.predicted_label)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN AUTOENCODER ###\n",
    "from training import trainAE, testAE, AutoEncoder\n",
    "learning_rate = 10**-3\n",
    "n_epochs = 30\n",
    "batch_size = 4\n",
    "\n",
    "AELeftHC = AutoEncoder()#.cuda()\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(AELeftHC.parameters(), learning_rate)\n",
    "\n",
    "best_AELeftHC = trainAE(AELeftHC, train_loaderLeftHC, criterion, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZATION ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "subject = 'sub-OASIS10003'\n",
    "preprocessed_pt = torch.load(f'/Users/camille.brianceau/Downloads/OASIS-1_dataset/CAPS/subjects/{subject}/ses-M00/' +\n",
    "                    'deeplearning_prepare_data/image_based/custom/' + subject +\n",
    "                    '_ses-M00_'+\n",
    "                    'T1w_segm-graymatter_space-Ixi549Space_modulated-off_' +\n",
    "                    'probability.pt')\n",
    "input_pt = CropLeftHC()(preprocessed_pt).unsqueeze(0)#.cuda()\n",
    "_, output_pt = best_AELeftHC(input_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ee302",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = input_pt[0, 0, 15, :, :].cpu()\n",
    "slice_1 = input_pt[0, 0, :, 20, :].cpu()\n",
    "slice_2 = input_pt[0, 0, :, :, 15].cpu()\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(f'Center slices of the input image of subject {subject}')\n",
    "plt.savefig(\"/Users/camille.brianceau/aramis/NOW-2023/figures/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c1c2c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "slice_0 = output_pt[0, 0, 15, :, :].cpu().detach()\n",
    "slice_1 = output_pt[0, 0, :, 20, :].cpu().detach()\n",
    "slice_2 = output_pt[0, 0, :, :, 15].cpu().detach()\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(f'Center slices of the output image of subject {subject}')\n",
    "plt.savefig(\"/Users/camille.brianceau/aramis/NOW-2023/figures/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36988720",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### CLUSTERING ###\n",
    "\n",
    "from training import compute_dataset_features\n",
    "# train_codes, train_labels, names = compute_dataset_features(train_loaderBothHC, best_AEBothHC)\n",
    "train_codes, train_labels, names = compute_dataset_features(train_loaderLeftHC, best_AELeftHC)\n",
    "\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "n_components = 2\n",
    "model = mixture.GaussianMixture(n_components)\n",
    "model.fit(train_codes)\n",
    "train_predict = model.predict(train_codes)\n",
    "\n",
    "metrics = compute_metrics(train_labels, train_predict)\n",
    "ari = adjusted_rand_score(train_labels, train_predict)\n",
    "print(f\"Adjusted random index: {ari}\")\n",
    "\n",
    "data_np = np.concatenate([names, train_codes,\n",
    "                          train_labels[:, np.newaxis],\n",
    "                          train_predict[:, np.newaxis]], axis=1)\n",
    "columns = ['feature %i' % i for i in range(train_codes.shape[1])]\n",
    "columns = ['participant_id'] + columns + ['true_label', 'predicted_label']\n",
    "data_df = pd.DataFrame(data_np, columns=columns).set_index('participant_id')\n",
    "\n",
    "merged_df = data_df.merge(OASIS_df.set_index('participant_id'), how='inner', on='participant_id')\n",
    "\n",
    "plt.title('Clustering values according to age and MMS score')\n",
    "for component in range(n_components):\n",
    "    predict_df = merged_df[merged_df.predicted_label == str(component)]\n",
    "    plt.plot(predict_df['age_bl'], predict_df['MMS'], 'o', label=f\"cluster {component}\")\n",
    "plt.legend()\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('MMS')\n",
    "plt.savefig(\"/Users/camille.brianceau/aramis/NOW-2023/figures/6.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
